{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# References: \n",
    "# https://github.com/fchollet/deep-learning-models/blob/master/resnet50.py\n",
    "# Andrew Ng Deep Learning Specialization\n",
    "# https://arxiv.org/abs/1512.03385"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.set_random_seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResNet50(object):\n",
    "    \n",
    "    def __init__(self,\n",
    "            sess,\n",
    "            input_dim=(64, 64, 3),\n",
    "            n_classes=10,\n",
    "            n_epochs=2,\n",
    "            batch_size=32,\n",
    "            initializer=tf.glorot_uniform_initializer(seed=0)):\n",
    "        self._sess = sess\n",
    "        self._input_dim = input_dim\n",
    "        self._n_classes = n_classes\n",
    "        self._n_epochs = n_epochs\n",
    "        self._batch_size = batch_size\n",
    "    \n",
    "        self._init = initializer\n",
    "        self._build_graph()\n",
    "        \n",
    "    def _identity_block(self, X, f, filters, stage, block):\n",
    "        \"\"\" Identity block where skip connection skips over 3 layers.\n",
    "        args:\n",
    "            X - Input tensor of shape (m, n_H_prev, n_W_prev, n_C_prev).\n",
    "            f - Integer, filter dimension used in 2nd component of main path.\n",
    "            filters - List of integers, defining # of filters in the CONV layer.\n",
    "            stage - Integer used to name the layers.\n",
    "            block - String used in naming layers.\n",
    "        rets:\n",
    "            X - Output of the identity block with shape (n_H, n_W, n_C)\n",
    "        \"\"\"\n",
    "        # defining name basis\n",
    "        conv_base = 'res' + str(stage) + block + '_branch'\n",
    "        bn_base = 'bn' + str(stage) + block + '_branch'\n",
    "        \n",
    "        # Retrieve Filters\n",
    "        F1, F2, F3 = filters\n",
    "        \n",
    "        # Save the input value.\n",
    "        X_input = X\n",
    " \n",
    "        # First component of main path\n",
    "        out = tf.layers.conv2d(X, F1, [1,1], (1,1), \"valid\", name=conv_base+'2a', kernel_initializer=self._init)\n",
    "        out = tf.layers.batch_normalization(out, axis=3, name=bn_base+'2a')\n",
    "        out = tf.nn.relu(out)\n",
    "        \n",
    "        # Second component of main path\n",
    "        out = tf.layers.conv2d(out, F2, [f,f], (1,1), \"same\", name=conv_base+'2b', kernel_initializer=self._init)\n",
    "        out = tf.layers.batch_normalization(out, axis=3, name=bn_base+'2b')\n",
    "        out = tf.nn.relu(out)\n",
    "        \n",
    "        # Third component of main path\n",
    "        out = tf.layers.conv2d(out, F3, [1,1], (1,1), \"valid\", name=conv_base+'2c', kernel_initializer=self._init)\n",
    "        out = tf.layers.batch_normalization(out, axis=3, name=bn_base+'2c')\n",
    "        \n",
    "        # Final step: Add the X_input to out\n",
    "        out = tf.keras.layers.add([out, X_input])\n",
    "        out = tf.nn.relu(out)\n",
    "        return out\n",
    "    \n",
    "    def _conv_block(self, X, f, filters, stage, block, s=2):\n",
    "        \"\"\" Convolution block.\n",
    "        args:\n",
    "            X - input tensor of shape (m, n_H_prev, n_W_prev, n_C_prev)\n",
    "            f - Integer, filter dimension used in 2nd component of main path.\n",
    "            filters - List of integers, defining # of filters in the CONV layer.\n",
    "            stage - Integer used to name the layers.\n",
    "            block - String used in naming layers.\n",
    "        rets:\n",
    "            X -- output of the convolutional block, tensor of shape (n_H, n_W, n_C)\n",
    "        \"\"\"\n",
    "        # defining name basis\n",
    "        conv_base = 'res' + str(stage) + block + '_branch'\n",
    "        bn_base = 'bn' + str(stage) + block + '_branch'\n",
    "        \n",
    "        # Retrieve Filters\n",
    "        F1, F2, F3 = filters\n",
    "        \n",
    "        # Save the input value.\n",
    "        X_input = X\n",
    "        \n",
    "        # First component of main path\n",
    "        out = tf.layers.conv2d(X, F1, [1,1], (s,s), \"valid\", name=conv_base+'2a', kernel_initializer=self._init)\n",
    "        out = tf.layers.batch_normalization(out, axis=3, name=bn_base+'2a')\n",
    "        out = tf.nn.relu(out)\n",
    "        \n",
    "        # Second component of main path\n",
    "        out = tf.layers.conv2d(out, F2, [f,f], (1,1), \"same\", name=conv_base+'2b', kernel_initializer=self._init)\n",
    "        out = tf.layers.batch_normalization(out, axis=3, name=bn_base+'2b')\n",
    "        out = tf.nn.relu(out)\n",
    "        \n",
    "        # Third component of main path\n",
    "        out = tf.layers.conv2d(out, F3, [1,1], (1,1), \"valid\", name=conv_base+'2c', kernel_initializer=self._init)\n",
    "        out = tf.layers.batch_normalization(out, axis=3, name=bn_base+'2c')\n",
    "        \n",
    "        # Skip path\n",
    "        out_skip = tf.layers.conv2d(X_input, F3, [1,1], (s,s), \"valid\", name=conv_base+'1', kernel_initializer=self._init)\n",
    "        out_skip = tf.layers.batch_normalization(out_skip, axis=3, name=bn_base+'1')\n",
    "        \n",
    "        out = tf.keras.layers.add([out, out_skip])\n",
    "        out = tf.nn.relu(out)\n",
    "        return out\n",
    "        \n",
    "    def _model(self, X_input):\n",
    "        \"\"\" ResNet-50.\n",
    "        args:\n",
    "            X - input tensor of shape (m, n_H_prev, n_W_prev, n_C_prev)\n",
    "        rets:\n",
    "            out - logits w/ out softmax\n",
    "        \"\"\"\n",
    "        out = tf.keras.layers.ZeroPadding2D(padding=(3,3)).call(X_input)\n",
    "    \n",
    "        initializer = tf.glorot_uniform_initializer(seed=0)\n",
    "        \n",
    "        # Stage 1\n",
    "        out = tf.layers.conv2d(out, 64, [7,7], (2,2), \"valid\", name='conv1', kernel_initializer=initializer)\n",
    "        out = tf.layers.batch_normalization(out, axis=3, name='bn_conv1')\n",
    "        out = tf.nn.relu(out)\n",
    "        \n",
    "        # Stage 2\n",
    "        out = self._conv_block(out, f = 3, filters = [64, 64, 256], stage = 2, block='a', s = 1)\n",
    "        out = self._identity_block(out, 3, [64, 64, 256], stage=2, block='b')\n",
    "        out = self._identity_block(out, 3, [64, 64, 256], stage=2, block='c')\n",
    "        \n",
    "        # Stage 3 \n",
    "        out = self._conv_block(out, f = 3, filters = [128, 128, 512], stage = 3, block='a', s = 2)\n",
    "        out = self._identity_block(out, 3, [128, 128, 512], stage=3, block='b')\n",
    "        out = self._identity_block(out, 3, [128, 128, 512], stage=3, block='c')\n",
    "        out = self._identity_block(out, 3, [128, 128, 512], stage=3, block='d')\n",
    "        \n",
    "        # Stage 4\n",
    "        out = self._conv_block(out, f = 3, filters = [256, 256, 1024], stage = 4, block='a', s = 2)\n",
    "        out = self._identity_block(out, 3, [256, 256, 1024], stage=4, block='b')\n",
    "        out = self._identity_block(out, 3, [256, 256, 1024], stage=4, block='c')\n",
    "        out = self._identity_block(out, 3, [256, 256, 1024], stage=4, block='d')\n",
    "        out = self._identity_block(out, 3, [256, 256, 1024], stage=4, block='e')\n",
    "        out = self._identity_block(out, 3, [256, 256, 1024], stage=4, block='f')\n",
    "\n",
    "        # Stage 5\n",
    "        out = self._conv_block(out, f = 3, filters = [512, 512, 2048], stage = 5, block='a', s = 2)\n",
    "        out = self._identity_block(out, 3, [512, 512, 2048], stage=5, block='b')\n",
    "        out = self._identity_block(out, 3, [512, 512, 2048], stage=5, block='c')\n",
    "        \n",
    "        out = tf.layers.AveragePooling2D(pool_size=(2, 2), strides=(1,1), padding='valid', name='avg_pool').call(out)\n",
    "        out = tf.layers.flatten(out)\n",
    "        # Note: softmax applied by tf.nn.softmax_cross_entropy_with_logits\n",
    "        out = tf.layers.dense(out, self._n_classes, name='fc' + str(self._n_classes), kernel_initializer=self._init)\n",
    "        return out\n",
    "        \n",
    "    def _build_graph(self):\n",
    "        \"\"\" Build graph and define placeholders and variables. \"\"\"\n",
    "        n_h, n_w, n_c = self._input_dim\n",
    "        self._inputs = tf.placeholder(\"float\", [None, n_h, n_w, n_c])\n",
    "        self._labels = tf.placeholder(\"float\", [None, self._n_classes])\n",
    "        self._global_step = tf.Variable(0, dtype=tf.int32, trainable=False, name='global_step')\n",
    "\n",
    "        self._logits = self._model(self._inputs)\n",
    "        self._loss = tf.nn.softmax_cross_entropy_with_logits(labels=self._labels, logits=self._logits)\n",
    "        self._train = tf.train.AdamOptimizer().minimize(self._loss, global_step=self._global_step)\n",
    "\n",
    "        \n",
    "    def _train_input_fn(self, X_train, y_train):\n",
    "        \"\"\" Utility to set up iterator for feed of batched train data.\n",
    "        args:\n",
    "            X_train - train input of dim (m, n_H_prev, n_W_prev, n_C_prev)\n",
    "            y_train - train labels of dim (m, n_classes)\n",
    "        rets:\n",
    "            iterator - iterator object\n",
    "            next_element - operation to get next from iterator\n",
    "        \"\"\"\n",
    "        def _one_hot(label):\n",
    "            return tf.gather(tf.one_hot(label, self._n_classes),0)\n",
    "    \n",
    "        images = tf.data.Dataset.from_tensor_slices(X_train)\n",
    "        labels = tf.data.Dataset.from_tensor_slices(y_train)\n",
    "        labels = labels.map(_one_hot)\n",
    "        dataset = tf.data.Dataset.zip((images, labels))\n",
    "        dataset = dataset.batch(self._batch_size)\n",
    "        iterator = dataset.make_initializable_iterator()\n",
    "        next_element = iterator.get_next()\n",
    "        return iterator, next_element\n",
    "    \n",
    "    def train(self, X_train, y_train):\n",
    "        \"\"\" Train\n",
    "        args:\n",
    "            X_train - train input of dim (m, n_H_prev, n_W_prev, n_C_prev)\n",
    "            y_train - train labels of dim (m, n_classes)\n",
    "        \"\"\"\n",
    "        tf.global_variables_initializer().run()\n",
    "        \n",
    "        train_iterator, train_next = self._train_input_fn(X_train, y_train)\n",
    "            \n",
    "        for epoch in range(self._n_epochs):\n",
    "            self._sess.run(train_iterator.initializer)\n",
    "            epoch_loss = np.array([])\n",
    "            while True:\n",
    "                try:\n",
    "                    img_batch, label_batch = self._sess.run(train_next)\n",
    "                    loss, _ = self._sess.run([self._loss, self._train],\n",
    "                                             feed_dict={\n",
    "                            self._inputs: img_batch,\n",
    "                            self._labels: label_batch}\n",
    "                    )\n",
    "                    epoch_loss = np.concatenate([epoch_loss,loss])\n",
    "                except tf.errors.OutOfRangeError:\n",
    "                    break\n",
    "                    \n",
    "            print(\"Epoch: {} Train Loss: {}\".format(\n",
    "                epoch, np.mean(np.array(epoch_loss)))\n",
    "            )\n",
    "    \n",
    "    def evaluate(self, X, y):\n",
    "        # Set up ops.\n",
    "        predict_op = tf.argmax(tf.nn.softmax(self._logits), 1)\n",
    "        correct_prediction = tf.equal(predict_op, tf.argmax(self._labels, 1))\n",
    "        accuracy = tf.reduce_mean(tf.cast(correct_prediction, \"float\"))\n",
    "        \n",
    "        # One hot encode y.\n",
    "        one_hot = lambda y_: np.eye(self._n_classes)[y_].flatten()\n",
    "        # Reshape to match dimensions of self._labels\n",
    "        y_one_hot = list(map(one_hot,y))\n",
    "        # Evaluate ops.\n",
    "        result = accuracy.eval({self._inputs: X, self._labels: y_one_hot})\n",
    "        return result\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "out = [ 0.94822985  0.          1.16101444  2.747859    0.          1.36677003]\n"
     ]
    }
   ],
   "source": [
    "# Test identity block\n",
    "\n",
    "tf.reset_default_graph()\n",
    "\n",
    "with tf.Session() as identity_sess:\n",
    "    np.random.seed(1)\n",
    "    A_prev = tf.placeholder(\"float\", [3, 4, 4, 6])\n",
    "    X = np.random.randn(3, 4, 4, 6)\n",
    "    model = ResNet50(identity_sess)\n",
    "    A = model._identity_block(A_prev, f = 2, filters = [2, 4, 6], stage = 1, block = 'a')\n",
    "    tf.global_variables_initializer().run()\n",
    "    result = identity_sess.run([A], feed_dict={A_prev: X })\n",
    "    print(\"out = \" + str(result[0][1][1][0]))\n",
    "    \n",
    "# out = [ 0.94822985  0.          1.16101444  2.747859    0.          1.36677003]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "out = [ 0.09018463  1.23489773  0.46822017  0.0367176   0.          0.65516603]\n"
     ]
    }
   ],
   "source": [
    "# Test convolution block\n",
    "\n",
    "tf.reset_default_graph()\n",
    "\n",
    "with tf.Session() as conv_sess:\n",
    "    np.random.seed(1)\n",
    "    A_prev = tf.placeholder(\"float\", [3, 4, 4, 6])\n",
    "    X = np.random.randn(3, 4, 4, 6)\n",
    "    model = ResNet50(conv_sess)\n",
    "    A = model._conv_block(A_prev, f = 2, filters = [2, 4, 6], stage = 1, block = 'a')\n",
    "    conv_sess.run(tf.global_variables_initializer())\n",
    "    out = conv_sess.run([A], feed_dict={A_prev: X})\n",
    "    print(\"out = \" + str(out[0][1][1][0]))\n",
    "# out = [ 0.09018463  1.23489773  0.46822017  0.0367176   0.          0.65516603]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.datasets import cifar10\n",
    "\n",
    "(X_train, y_train), (X_test, y_test) = cifar10.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of training examples = 50000\n",
      "number of test examples = 10000\n",
      "X_train shape: (50000, 32, 32, 3)\n",
      "Y_train shape: (50000, 1)\n",
      "X_test shape: (10000, 32, 32, 3)\n",
      "Y_test shape: (10000, 1)\n"
     ]
    }
   ],
   "source": [
    "print(\"number of training examples = \" + str(X_train.shape[0]))\n",
    "print(\"number of test examples = \" + str(X_test.shape[0]))\n",
    "print(\"X_train shape: \" + str(X_train.shape))\n",
    "print(\"Y_train shape: \" + str(y_train.shape))\n",
    "print(\"X_test shape: \" + str(X_test.shape))\n",
    "print(\"Y_test shape: \" + str(y_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample smaller set if testing on CPU\n",
    "n_cpu = 1000\n",
    "X_cpu = X_train[:n_cpu]\n",
    "y_cpu = y_train[:n_cpu]\n",
    "X_test_cpu = X_test[:n_cpu]\n",
    "y_test_cpu = y_test[:n_cpu]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 Train Loss: 35.99907213047441\n",
      "Epoch: 1 Train Loss: 2.2643281412124634\n",
      "Epoch: 2 Train Loss: 2.118570439577103\n",
      "Epoch: 3 Train Loss: 1.989766313880682\n",
      "Epoch: 4 Train Loss: 1.888827444076538\n",
      "Accuracy: 0.28999999165534973\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "with tf.Session() as sess:\n",
    "    model = ResNet50(sess, input_dim=(32,32,3), n_epochs=5)\n",
    "    model.train(X_cpu, y_cpu)\n",
    "    result = model.evaluate(X_test_cpu, y_test_cpu)\n",
    "    print(\"Accuracy: {}\".format(result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
