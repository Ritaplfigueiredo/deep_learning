{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from config import config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://arxiv.org/pdf/1704.07911.pdf\n",
    "# https://arxiv.org/pdf/1708.03798.pdf\n",
    "# data: https://github.com/udacity/self-driving-car/tree/master/datasets/CH2\n",
    "# scripts to convert rosbags to csv: https://github.com/rwightman/udacity-driving-reader\n",
    "\n",
    "# TODO: \n",
    "# 1. Input image need to be changed to YUV (img_yuv = cv2.cvtColor(image, cv2.COLOR_BGR2YUV))\n",
    "# 2. Cropping to 200 x 66 per paper\n",
    "# 3. Figure out proper steps for training per epoch.\n",
    "# 4. Split data into train and validation.\n",
    "# 5. Incorporate testing framework.\n",
    "# 6. Incorporate visualization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['frame_id', 'filename', 'angle']"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "csv_header = \"index,timestamp,width,height,frame_id,filename,angle,torque,speed,lat,long,alt\".split(\",\")\n",
    "csv_header[-8:-5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "home = config['bag4']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def input_fn(file_path):    \n",
    "    def decode_csv(line):\n",
    "        # tf.decode_csv needs a record_default as 2nd parameter\n",
    "        data = tf.decode_csv(line,  list(np.array([\"\"]*12).reshape(12,1)))[-8:-5]\n",
    "        img_path = home+data[1]\n",
    "        img_decoded = tf.to_float(tf.image.decode_image(tf.read_file(img_path)))\n",
    "        \n",
    "        # normalize between (-1,1)\n",
    "        img_decoded = -1.0 + 2.0 * img_decoded / 255.0\n",
    "        steer_angle = tf.string_to_number(data[2], tf.float32)\n",
    "        \n",
    "        # return camera as well to confirm location of camera \n",
    "        # e.g left_camera, center_camera, right_camera...we want center_camera\n",
    "        return {'image':  img_decoded, 'camera': data[0]}, [steer_angle]\n",
    "\n",
    "    # skip() header row,\n",
    "    # filter() for center camera,\n",
    "    # map() transform each line by applying decode_csv()\n",
    "    dataset = (tf.data.TextLineDataset(file_path) \n",
    "        .skip(1) \n",
    "        .filter(lambda x: tf.equal(\n",
    "            tf.string_split(tf.reshape(x,(1,)),',').values[4],\n",
    "            'center_camera'))\n",
    "        .map(decode_csv)) \n",
    "               \n",
    "    return dataset\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path=home+\"interpolated.csv\"\n",
    "dataset = input_fn(file_path)\n",
    "dataset = dataset.batch(32) \n",
    "batch_generator = dataset.make_one_shot_iterator()\n",
    "batch = batch_generator.get_next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.Session() as sess:\n",
    "    sample = sess.run(batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['center_camera', 'center_camera', 'center_camera', 'center_camera',\n",
       "       'center_camera', 'center_camera', 'center_camera', 'center_camera',\n",
       "       'center_camera', 'center_camera', 'center_camera', 'center_camera',\n",
       "       'center_camera', 'center_camera', 'center_camera', 'center_camera',\n",
       "       'center_camera', 'center_camera', 'center_camera', 'center_camera',\n",
       "       'center_camera', 'center_camera', 'center_camera', 'center_camera',\n",
       "       'center_camera', 'center_camera', 'center_camera', 'center_camera',\n",
       "       'center_camera', 'center_camera', 'center_camera', 'center_camera'], dtype=object)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# confirm only center camera data returned.\n",
    "sample[0]['camera']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    " class PilotNet(object):\n",
    "    \n",
    "    def __init__(self, sess, log_dir, ckpt_dir, n_epochs, batch_size):\n",
    "        self._sess = sess\n",
    "        self._log_dir = log_dir\n",
    "        self._ckpt_dir = ckpt_dir\n",
    "        self._n_epochs = n_epochs\n",
    "        self._batch_size = batch_size\n",
    "        self._build_graph()\n",
    "\n",
    "    def _model(self, x):\n",
    "        assert(x[0].shape == (480,640,3))\n",
    "        out = tf.layers.batch_normalization(x)\n",
    "        out = tf.layers.conv2d(x, 24, [5,5], (2,2), \"valid\", activation=tf.nn.relu)\n",
    "        out = tf.layers.conv2d(out, 36, [5,5], (2,2), \"valid\", activation=tf.nn.relu)\n",
    "        out = tf.layers.conv2d(out, 48, [5,5], (2,2), \"valid\", activation=tf.nn.relu)\n",
    "        out = tf.layers.conv2d(out, 64, [3,3], (1,1), \"valid\", activation=tf.nn.relu)\n",
    "        out = tf.layers.conv2d(out, 64, [3,3], (1,1), \"valid\", activation=tf.nn.relu)\n",
    "        out = tf.reshape(out, [-1, 64*53*73])\n",
    "        out = tf.layers.dense(out, 100, tf.nn.relu) \n",
    "        out = tf.layers.dense(out, 50, tf.nn.relu) \n",
    "        out = tf.layers.dense(out, 10, tf.nn.relu) \n",
    "        out = tf.layers.dense(out, 1)\n",
    "        return out\n",
    "    \n",
    "    def _build_graph(self):\n",
    "        self._inputs = tf.placeholder(\"float\", [None, 480, 640, 3])\n",
    "        self._targets = tf.placeholder(\"float\", [None, 1])\n",
    "        self._global_step = tf.Variable(0, dtype=tf.int32, trainable=False, name='global_step')\n",
    "\n",
    "        self._predict = self._model(self._inputs)\n",
    "        self._loss = tf.losses.mean_squared_error(labels=self._targets, predictions=self._predict)\n",
    "        self._train =  tf.train.AdamOptimizer().minimize(self._loss, global_step=self._global_step)\n",
    "\n",
    "    def _train_admin_setup(self):\n",
    "        # Writers\n",
    "        self._train_writer = tf.summary.FileWriter(self._log_dir + '/train', self._sess.graph)\n",
    "\n",
    "        # Saver\n",
    "        self._saver = tf.train.Saver()\n",
    "\n",
    "        # Summaries\n",
    "        tf.summary.scalar(\"loss\", self._loss)\n",
    "        self._all_summaries = tf.summary.merge_all()\n",
    "        \n",
    "    def train(self, file_path):\n",
    "        self._train_admin_setup()\n",
    "        tf.global_variables_initializer().run()\n",
    "        \n",
    "        # Check if there is a previously saved checkpoint\n",
    "        ckpt = tf.train.get_checkpoint_state(os.path.dirname(self._ckpt_path))\n",
    "        if ckpt and ckpt.model_checkpoint_path:\n",
    "            self._saver.restore(self._sess, ckpt.model_checkpoint_path)\n",
    "        \n",
    "        # Train\n",
    "        for epoch in range(self._n_epochs):\n",
    "            dataset = input_fn(file_path)\n",
    "            dataset = dataset.batch(self._batch_size)\n",
    "            batch_generator = dataset.make_one_shot_iterator()\n",
    "            epoch_loss = []\n",
    "            while True:\n",
    "                try: \n",
    "                    img_batch, label_batch = self._sess.run(batch_generator.get_next())\n",
    "\n",
    "                    loss, _ = self._sess.run([self._loss, self._train], feed_dict={\n",
    "                        self._inputs: img_batch['image'], \n",
    "                        self._targets: label_batch}\n",
    "                    )\n",
    "                    epoch_loss.append(loss)\n",
    "                except tf.errors.OutOfRangeError:\n",
    "                    break\n",
    "                            \n",
    "            # Add summary and save checkpoint after every epoch\n",
    "            s = self._sess.run(self._all_summaries, feed_dict={\n",
    "                self._inputs : img_batch['image'],\n",
    "                self._targets: label_batch}\n",
    "            )\n",
    "            self._train_writer.add_summary(s, global_step=epoch)\n",
    "            self._saver.save(self._sess, self._ckpt_dir, global_step=self._global_step)\n",
    "            print(\"Epoch: {} Loss: {}\".format(epoch, np.mean(epoch_loss)))\n",
    "\n",
    "\n",
    "        # Need to closer writers\n",
    "        self._train_writer.close()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 Loss: 0.0521120642084\n",
      "Epoch: 1 Loss: 0.0234290816515\n",
      "Epoch: 2 Loss: 0.0221254225422\n",
      "Epoch: 3 Loss: 0.0208233818121\n",
      "Epoch: 4 Loss: 0.019718508896\n"
     ]
    },
    {
     "ename": "ResourceExhaustedError",
     "evalue": "checkpoints/pilot_net-120.data-00000-of-00001.tempstate17954737183548979135; No space left on device\n\t [[Node: save/SaveV2 = SaveV2[dtypes=[DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_INT32], _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](_arg_save/Const_0_0, save/SaveV2/tensor_names, save/SaveV2/shape_and_slices, batch_normalization/beta, batch_normalization/gamma, batch_normalization/moving_mean, batch_normalization/moving_variance, beta1_power, beta2_power, conv2d/bias, conv2d/bias/Adam, conv2d/bias/Adam_1, conv2d/kernel, conv2d/kernel/Adam, conv2d/kernel/Adam_1, conv2d_1/bias, conv2d_1/bias/Adam, conv2d_1/bias/Adam_1, conv2d_1/kernel, conv2d_1/kernel/Adam, conv2d_1/kernel/Adam_1, conv2d_2/bias, conv2d_2/bias/Adam, conv2d_2/bias/Adam_1, conv2d_2/kernel, conv2d_2/kernel/Adam, conv2d_2/kernel/Adam_1, conv2d_3/bias, conv2d_3/bias/Adam, conv2d_3/bias/Adam_1, conv2d_3/kernel, conv2d_3/kernel/Adam, conv2d_3/kernel/Adam_1, conv2d_4/bias, conv2d_4/bias/Adam, conv2d_4/bias/Adam_1, conv2d_4/kernel, conv2d_4/kernel/Adam, conv2d_4/kernel/Adam_1, dense/bias, dense/bias/Adam, dense/bias/Adam_1, dense/kernel, dense/kernel/Adam, dense/kernel/Adam_1, dense_1/bias, dense_1/bias/Adam, dense_1/bias/Adam_1, dense_1/kernel, dense_1/kernel/Adam, dense_1/kernel/Adam_1, dense_2/bias, dense_2/bias/Adam, dense_2/bias/Adam_1, dense_2/kernel, dense_2/kernel/Adam, dense_2/kernel/Adam_1, dense_3/bias, dense_3/bias/Adam, dense_3/bias/Adam_1, dense_3/kernel, dense_3/kernel/Adam, dense_3/kernel/Adam_1, global_step)]]\n\nCaused by op u'save/SaveV2', defined at:\n  File \"/usr/lib/python2.7/runpy.py\", line 174, in _run_module_as_main\n    \"__main__\", fname, loader, pkg_name)\n  File \"/usr/lib/python2.7/runpy.py\", line 72, in _run_code\n    exec code in run_globals\n  File \"/usr/local/lib/python2.7/dist-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/usr/local/lib/python2.7/dist-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/usr/local/lib/python2.7/dist-packages/ipykernel/kernelapp.py\", line 477, in start\n    ioloop.IOLoop.instance().start()\n  File \"/usr/local/lib/python2.7/dist-packages/zmq/eventloop/ioloop.py\", line 177, in start\n    super(ZMQIOLoop, self).start()\n  File \"/usr/local/lib/python2.7/dist-packages/tornado/ioloop.py\", line 888, in start\n    handler_func(fd_obj, events)\n  File \"/usr/local/lib/python2.7/dist-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/usr/local/lib/python2.7/dist-packages/zmq/eventloop/zmqstream.py\", line 440, in _handle_events\n    self._handle_recv()\n  File \"/usr/local/lib/python2.7/dist-packages/zmq/eventloop/zmqstream.py\", line 472, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/usr/local/lib/python2.7/dist-packages/zmq/eventloop/zmqstream.py\", line 414, in _run_callback\n    callback(*args, **kwargs)\n  File \"/usr/local/lib/python2.7/dist-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/usr/local/lib/python2.7/dist-packages/ipykernel/kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/usr/local/lib/python2.7/dist-packages/ipykernel/kernelbase.py\", line 235, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/usr/local/lib/python2.7/dist-packages/ipykernel/kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"/usr/local/lib/python2.7/dist-packages/ipykernel/ipkernel.py\", line 196, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/usr/local/lib/python2.7/dist-packages/ipykernel/zmqshell.py\", line 533, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/usr/local/lib/python2.7/dist-packages/IPython/core/interactiveshell.py\", line 2718, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/usr/local/lib/python2.7/dist-packages/IPython/core/interactiveshell.py\", line 2822, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/usr/local/lib/python2.7/dist-packages/IPython/core/interactiveshell.py\", line 2882, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-41-25e13ae9c2f5>\", line 5, in <module>\n    model.train(file_path)\n  File \"<ipython-input-40-abad96d285eb>\", line 46, in train\n    self._train_admin_setup()\n  File \"<ipython-input-40-abad96d285eb>\", line 39, in _train_admin_setup\n    self._saver = tf.train.Saver()\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/saver.py\", line 1218, in __init__\n    self.build()\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/saver.py\", line 1227, in build\n    self._build(self._filename, build_save=True, build_restore=True)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/saver.py\", line 1263, in _build\n    build_save=build_save, build_restore=build_restore)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/saver.py\", line 748, in _build_internal\n    save_tensor = self._AddSaveOps(filename_tensor, saveables)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/saver.py\", line 296, in _AddSaveOps\n    save = self.save_op(filename_tensor, saveables)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/saver.py\", line 239, in save_op\n    tensors)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/gen_io_ops.py\", line 1163, in save_v2\n    shape_and_slices=shape_and_slices, tensors=tensors, name=name)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.py\", line 2956, in create_op\n    op_def=op_def)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.py\", line 1470, in __init__\n    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access\n\nResourceExhaustedError (see above for traceback): checkpoints/pilot_net-120.data-00000-of-00001.tempstate17954737183548979135; No space left on device\n\t [[Node: save/SaveV2 = SaveV2[dtypes=[DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_INT32], _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](_arg_save/Const_0_0, save/SaveV2/tensor_names, save/SaveV2/shape_and_slices, batch_normalization/beta, batch_normalization/gamma, batch_normalization/moving_mean, batch_normalization/moving_variance, beta1_power, beta2_power, conv2d/bias, conv2d/bias/Adam, conv2d/bias/Adam_1, conv2d/kernel, conv2d/kernel/Adam, conv2d/kernel/Adam_1, conv2d_1/bias, conv2d_1/bias/Adam, conv2d_1/bias/Adam_1, conv2d_1/kernel, conv2d_1/kernel/Adam, conv2d_1/kernel/Adam_1, conv2d_2/bias, conv2d_2/bias/Adam, conv2d_2/bias/Adam_1, conv2d_2/kernel, conv2d_2/kernel/Adam, conv2d_2/kernel/Adam_1, conv2d_3/bias, conv2d_3/bias/Adam, conv2d_3/bias/Adam_1, conv2d_3/kernel, conv2d_3/kernel/Adam, conv2d_3/kernel/Adam_1, conv2d_4/bias, conv2d_4/bias/Adam, conv2d_4/bias/Adam_1, conv2d_4/kernel, conv2d_4/kernel/Adam, conv2d_4/kernel/Adam_1, dense/bias, dense/bias/Adam, dense/bias/Adam_1, dense/kernel, dense/kernel/Adam, dense/kernel/Adam_1, dense_1/bias, dense_1/bias/Adam, dense_1/bias/Adam_1, dense_1/kernel, dense_1/kernel/Adam, dense_1/kernel/Adam_1, dense_2/bias, dense_2/bias/Adam, dense_2/bias/Adam_1, dense_2/kernel, dense_2/kernel/Adam, dense_2/kernel/Adam_1, dense_3/bias, dense_3/bias/Adam, dense_3/bias/Adam_1, dense_3/kernel, dense_3/kernel/Adam, dense_3/kernel/Adam_1, global_step)]]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-41-25e13ae9c2f5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSession\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPilotNet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"pilot_net\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10\u001b[0m \u001b[0;34m,\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-40-abad96d285eb>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, file_path)\u001b[0m\n\u001b[1;32m     70\u001b[0m            )\n\u001b[1;32m     71\u001b[0m            \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_train_writer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_summary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mglobal_step\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m            \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_saver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'checkpoints/pilot_net'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mglobal_step\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_global_step\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m            \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Epoch: {} Loss: {}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/saver.pyc\u001b[0m in \u001b[0;36msave\u001b[0;34m(self, sess, save_path, global_step, latest_filename, meta_graph_suffix, write_meta_graph, write_state)\u001b[0m\n\u001b[1;32m   1571\u001b[0m           model_checkpoint_path = sess.run(\n\u001b[1;32m   1572\u001b[0m               \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msaver_def\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_tensor_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1573\u001b[0;31m               {self.saver_def.filename_tensor_name: checkpoint_file})\n\u001b[0m\u001b[1;32m   1574\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1575\u001b[0m           self._build_eager(\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    887\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 889\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    890\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    891\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1118\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1119\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1120\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1121\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1122\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1315\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1316\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[0;32m-> 1317\u001b[0;31m                            options, run_metadata)\n\u001b[0m\u001b[1;32m   1318\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1319\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1334\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1335\u001b[0m           \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1336\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1337\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1338\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mResourceExhaustedError\u001b[0m: checkpoints/pilot_net-120.data-00000-of-00001.tempstate17954737183548979135; No space left on device\n\t [[Node: save/SaveV2 = SaveV2[dtypes=[DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_INT32], _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](_arg_save/Const_0_0, save/SaveV2/tensor_names, save/SaveV2/shape_and_slices, batch_normalization/beta, batch_normalization/gamma, batch_normalization/moving_mean, batch_normalization/moving_variance, beta1_power, beta2_power, conv2d/bias, conv2d/bias/Adam, conv2d/bias/Adam_1, conv2d/kernel, conv2d/kernel/Adam, conv2d/kernel/Adam_1, conv2d_1/bias, conv2d_1/bias/Adam, conv2d_1/bias/Adam_1, conv2d_1/kernel, conv2d_1/kernel/Adam, conv2d_1/kernel/Adam_1, conv2d_2/bias, conv2d_2/bias/Adam, conv2d_2/bias/Adam_1, conv2d_2/kernel, conv2d_2/kernel/Adam, conv2d_2/kernel/Adam_1, conv2d_3/bias, conv2d_3/bias/Adam, conv2d_3/bias/Adam_1, conv2d_3/kernel, conv2d_3/kernel/Adam, conv2d_3/kernel/Adam_1, conv2d_4/bias, conv2d_4/bias/Adam, conv2d_4/bias/Adam_1, conv2d_4/kernel, conv2d_4/kernel/Adam, conv2d_4/kernel/Adam_1, dense/bias, dense/bias/Adam, dense/bias/Adam_1, dense/kernel, dense/kernel/Adam, dense/kernel/Adam_1, dense_1/bias, dense_1/bias/Adam, dense_1/bias/Adam_1, dense_1/kernel, dense_1/kernel/Adam, dense_1/kernel/Adam_1, dense_2/bias, dense_2/bias/Adam, dense_2/bias/Adam_1, dense_2/kernel, dense_2/kernel/Adam, dense_2/kernel/Adam_1, dense_3/bias, dense_3/bias/Adam, dense_3/bias/Adam_1, dense_3/kernel, dense_3/kernel/Adam, dense_3/kernel/Adam_1, global_step)]]\n\nCaused by op u'save/SaveV2', defined at:\n  File \"/usr/lib/python2.7/runpy.py\", line 174, in _run_module_as_main\n    \"__main__\", fname, loader, pkg_name)\n  File \"/usr/lib/python2.7/runpy.py\", line 72, in _run_code\n    exec code in run_globals\n  File \"/usr/local/lib/python2.7/dist-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/usr/local/lib/python2.7/dist-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/usr/local/lib/python2.7/dist-packages/ipykernel/kernelapp.py\", line 477, in start\n    ioloop.IOLoop.instance().start()\n  File \"/usr/local/lib/python2.7/dist-packages/zmq/eventloop/ioloop.py\", line 177, in start\n    super(ZMQIOLoop, self).start()\n  File \"/usr/local/lib/python2.7/dist-packages/tornado/ioloop.py\", line 888, in start\n    handler_func(fd_obj, events)\n  File \"/usr/local/lib/python2.7/dist-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/usr/local/lib/python2.7/dist-packages/zmq/eventloop/zmqstream.py\", line 440, in _handle_events\n    self._handle_recv()\n  File \"/usr/local/lib/python2.7/dist-packages/zmq/eventloop/zmqstream.py\", line 472, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/usr/local/lib/python2.7/dist-packages/zmq/eventloop/zmqstream.py\", line 414, in _run_callback\n    callback(*args, **kwargs)\n  File \"/usr/local/lib/python2.7/dist-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/usr/local/lib/python2.7/dist-packages/ipykernel/kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/usr/local/lib/python2.7/dist-packages/ipykernel/kernelbase.py\", line 235, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/usr/local/lib/python2.7/dist-packages/ipykernel/kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"/usr/local/lib/python2.7/dist-packages/ipykernel/ipkernel.py\", line 196, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/usr/local/lib/python2.7/dist-packages/ipykernel/zmqshell.py\", line 533, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/usr/local/lib/python2.7/dist-packages/IPython/core/interactiveshell.py\", line 2718, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/usr/local/lib/python2.7/dist-packages/IPython/core/interactiveshell.py\", line 2822, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/usr/local/lib/python2.7/dist-packages/IPython/core/interactiveshell.py\", line 2882, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-41-25e13ae9c2f5>\", line 5, in <module>\n    model.train(file_path)\n  File \"<ipython-input-40-abad96d285eb>\", line 46, in train\n    self._train_admin_setup()\n  File \"<ipython-input-40-abad96d285eb>\", line 39, in _train_admin_setup\n    self._saver = tf.train.Saver()\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/saver.py\", line 1218, in __init__\n    self.build()\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/saver.py\", line 1227, in build\n    self._build(self._filename, build_save=True, build_restore=True)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/saver.py\", line 1263, in _build\n    build_save=build_save, build_restore=build_restore)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/saver.py\", line 748, in _build_internal\n    save_tensor = self._AddSaveOps(filename_tensor, saveables)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/saver.py\", line 296, in _AddSaveOps\n    save = self.save_op(filename_tensor, saveables)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/saver.py\", line 239, in save_op\n    tensors)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/gen_io_ops.py\", line 1163, in save_v2\n    shape_and_slices=shape_and_slices, tensors=tensors, name=name)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.py\", line 2956, in create_op\n    op_def=op_def)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.py\", line 1470, in __init__\n    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access\n\nResourceExhaustedError (see above for traceback): checkpoints/pilot_net-120.data-00000-of-00001.tempstate17954737183548979135; No space left on device\n\t [[Node: save/SaveV2 = SaveV2[dtypes=[DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_INT32], _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](_arg_save/Const_0_0, save/SaveV2/tensor_names, save/SaveV2/shape_and_slices, batch_normalization/beta, batch_normalization/gamma, batch_normalization/moving_mean, batch_normalization/moving_variance, beta1_power, beta2_power, conv2d/bias, conv2d/bias/Adam, conv2d/bias/Adam_1, conv2d/kernel, conv2d/kernel/Adam, conv2d/kernel/Adam_1, conv2d_1/bias, conv2d_1/bias/Adam, conv2d_1/bias/Adam_1, conv2d_1/kernel, conv2d_1/kernel/Adam, conv2d_1/kernel/Adam_1, conv2d_2/bias, conv2d_2/bias/Adam, conv2d_2/bias/Adam_1, conv2d_2/kernel, conv2d_2/kernel/Adam, conv2d_2/kernel/Adam_1, conv2d_3/bias, conv2d_3/bias/Adam, conv2d_3/bias/Adam_1, conv2d_3/kernel, conv2d_3/kernel/Adam, conv2d_3/kernel/Adam_1, conv2d_4/bias, conv2d_4/bias/Adam, conv2d_4/bias/Adam_1, conv2d_4/kernel, conv2d_4/kernel/Adam, conv2d_4/kernel/Adam_1, dense/bias, dense/bias/Adam, dense/bias/Adam_1, dense/kernel, dense/kernel/Adam, dense/kernel/Adam_1, dense_1/bias, dense_1/bias/Adam, dense_1/bias/Adam_1, dense_1/kernel, dense_1/kernel/Adam, dense_1/kernel/Adam_1, dense_2/bias, dense_2/bias/Adam, dense_2/bias/Adam_1, dense_2/kernel, dense_2/kernel/Adam, dense_2/kernel/Adam_1, dense_3/bias, dense_3/bias/Adam, dense_3/bias/Adam_1, dense_3/kernel, dense_3/kernel/Adam, dense_3/kernel/Adam_1, global_step)]]\n"
     ]
    }
   ],
   "source": [
    "file_path=home+\"interpolated.csv\"\n",
    "tf.reset_default_graph()\n",
    "with tf.Session() as sess:\n",
    "    saver.restore(sess,\n",
    "    model = PilotNet(sess,'pilot_net', 'checkpoints/pilot_net', 10 ,32)\n",
    "    model.train(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
